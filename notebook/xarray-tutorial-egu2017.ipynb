{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [SC57 - Working with big, multi-dimensional geoscientific datasets in Python: a tutorial introduction to xarray](http://meetingorganizer.copernicus.org/EGU2017/session/25651)  \n",
    "  \n",
    "  \n",
    "Original notebook by [Stephan Hoyer](http://stephanhoyer.com), Rossbypalooza, 2016.  \n",
    "Modified by Edward Byers, Matthew Gidden and [Fabien Maussion](http://fabienmaussion.info/) for EGU General Assembly 2017, Vienna, Austria\n",
    "\n",
    "\n",
    "  \n",
    "  Thursday, 27th April, 15:30â€“17:00 / Room -2.91  \n",
    "  \n",
    "  \n",
    "**Convenors**\n",
    "* [Dr Edward Byers](byers@iiasa.ac.at)    - International Institute for Applied Systems Analysis, Laxenburg, Austria\n",
    "* [Dr Matthew Gidden](gidden@iiasa.ac.at)  - International Institute for Applied Systems Analysis, Laxenburg, Austria\n",
    "* [Dr Fabien Maussion](fabien.maussion@uibk.ac.at) - University of Innsbruck, Innsbruck, Austria\n",
    "-------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./figures/dataset-diagram-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of this tutorial\n",
    "\n",
    "1. Introduction to key features of `xarray`\n",
    "2. Basic operations in xarray: opening, inspecting, selecting and indexing data\n",
    "3. Working with multiple datasets and computation\n",
    "4. Introduction to out-of-core computation\n",
    "5. Working with `pandas` and other packages\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Key features of `xarray`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is `xarray`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  `xarray` is an open source project and Python package\n",
    "*  `xarray` has been designed to perform **labelled** data analysis on **multi-dimensional** arrays\n",
    "* the xarray approach adopts the Common Data Model for **self-describing scientific data** in widespread use in the Earth sciences\n",
    "*  `xarray.Dataset` is an in-memory representation of a netCDF file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is `xarray` good for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gridded, multi-dimensional and large datasets, commonly used in earth sciences, but also increasingly finance, engineering (signal/image processing), and biological sciences\n",
    "* Integration with other data analysis packages such as Pandas \n",
    "* I/O operations (NetCDF)\n",
    "* Plotting\n",
    "* Out of core computation and parallel processing\n",
    "* Extensions based on xarray\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where can I find more info?\n",
    "This notebook introduces xarray for new users in the geophysical sciences.\n",
    "\n",
    "### For more information about xarray\n",
    "\n",
    "- Read the [online documentation](http://xarray.pydata.org/)\n",
    "- Ask questions on [StackOverflow](http://stackoverflow.com/questions/tagged/python-xarray)\n",
    "- View the source code and file bug reports on [GitHub](http://github.com/pydata/xarray/)\n",
    "\n",
    "### For more doing data analysis with Python:\n",
    "\n",
    "- Thomas Wiecki, [A modern guide to getting started with Data Science and Python](http://twiecki.github.io/blog/2014/11/18/python-for-data-science/)\n",
    "- Wes McKinney, [Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do) (book)\n",
    "\n",
    "### Packages building on xarray for the geophysical sciences\n",
    "\n",
    "For analyzing GCM output:\n",
    "\n",
    "- [xgcm](https://github.com/xgcm/xgcm) by Ryan Abernathey\n",
    "- [oogcm](https://github.com/lesommer/oocgcm) by Julien Le Sommer\n",
    "- [MPAS xarray](https://github.com/pwolfram/mpas_xarray) by Phil Wolfram\n",
    "- [marc_analysis](https://github.com/darothen/marc_analysis) by Daniel Rothenberg\n",
    "\n",
    "Other tools:\n",
    "\n",
    "- [windspharm](https://github.com/ajdawson/windspharm): wind spherical harmonics by Andrew Dawson\n",
    "- [eofs](https://github.com/ajdawson/eofs): empirical orthogonal functions by Andrew Dawson\n",
    "- [infinite-diff](https://github.com/spencerahill/infinite-diff) by Spencer Hill \n",
    "- [aospy](https://github.com/spencerahill/aospy) by Spencer Hill and Spencer Clark\n",
    "- [regionmask](https://github.com/mathause/regionmask) by Mathias Hauser\n",
    "- [salem](https://github.com/fmaussion/salem) by Fabien Maussion\n",
    "\n",
    "Resources for teaching and learning xarray in geosciences:\n",
    "- [Fabien's teaching repo](https://github.com/fmaussion/teaching): courses that combine teaching climatology and xarray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Basic operations in `xarray`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# np.set_printoptions(precision=3, linewidth=80, edgeitems=1)  # make numpy less verbose\n",
    "# xr.set_options(line_width=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data arrays in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1, 3, 9], [2, 8, 4]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our data\n",
    "\n",
    "<img src=\"./figures/dataset.png\" width=\"50%\" align=\"right\"> \n",
    "\n",
    "- numeric\n",
    "- multi-dimensional\n",
    "- labelled\n",
    "- (lots of) metadata\n",
    "- sometimes (very) large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `xarray.Dataset` is a container for multiple `xarray.DataArray` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the \"air_temperature\" tutorial dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = xr.tutorial.load_dataset('air_temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.values  #type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.air.attrs['tutorial-date']=24042017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xarray.Datasets with multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'ERA-Int-MonthlyAvg-4D-TUVWZ.nc'\n",
    "dse = xr.open_dataset(f)\n",
    "dse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting data with named dimensions\n",
    "\n",
    "In xarray there are many different ways for selecting and indexing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at the \"t\" variable\n",
    "dse.t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional indexing (old way)\n",
    "\n",
    "This is the \"old way\", i.e. like ``numpy``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dse.t[1, 2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This selection implies prior knowledge about the structure of the data, and is therefore much less readable than the \"xarray methods\" presented below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by index \n",
    "\n",
    "Selection based on the location (*index*), but with the dimension name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dse.t.isel(month=7, level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is already much more readable. But there is more:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by value\n",
    "\n",
    "Selection based on the **value** of a coordinate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dse.t.sel(month=7, longitude=-178.5, level=200)  # units are month, degrees, and hPa!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by value works well for time, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.sel(time='2013-01-02T06:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.sel(time='2013-01-02')  # Note that we will extract 4 time steps!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a range of values\n",
    "The syntax is similar, but you'll need to use a [slice](https://docs.python.org/3/library/functions.html#slice):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.sel(lat=slice(60, 50), lon=slice(200, 270), time='2013-01-02T06:00:00').plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbor lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.sel(lat=41.8781, lon=360-87.6298, method='nearest', tolerance=5).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Operations and computation\n",
    "\n",
    "* We can do arithmetic directly on `Dataset` and `DataArray` objects. \n",
    "* Labels are preserved and dataArray dimensions automatically aligned.\n",
    "* We can open multiple datasets easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dse.u.mean(dim=['month', 'longitude']).plot.contourf(levels=13)\n",
    "plt.ylim([1000, 100]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking with `.where()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_avg = ds.u.mean(dim=['month', 'longitude'])\n",
    "u_avg_masked = u_avg.where(u_avg > 12)\n",
    "u_avg_masked.plot.contourf(levels=13)\n",
    "plt.ylim([1000, 100]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Broadcasting\n",
    "\n",
    "<img src=\"./figures/broadcast.png\" width=\"50%\" align=\"left\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = xr.DataArray(np.arange(3), dims='time', \n",
    "                 coords={'time':np.arange(3)})\n",
    "b = xr.DataArray(np.arange(4), dims='space', \n",
    "                 coords={'space':np.arange(4)})\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Alignment\n",
    "\n",
    "<img src=\"./figures/align.png\" width=\"50%\" align=\"left\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = xr.DataArray(np.arange(3), dims='time', \n",
    "                 coords={'time':np.arange(3)})\n",
    "b = xr.DataArray(np.arange(5), dims='time', \n",
    "                 coords={'time':np.arange(5)+1})\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also apply NumPy \"universal functions\" like `np.sqrt` to `DataArray` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(ds.air)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xarray also implements standard aggregation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.median(dim=['lat', 'lon']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average everything over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.mean(dim='time')#.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change from Kelvin to degrees C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds.air.mean(dim='time')-273.16)#.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice xarray has changed the colormap according to the dataset (borrowing logic from Seaborn).\n",
    "* With degrees C, the data passes through 0, so a diverging colormap is used\n",
    "* With Kelvin, the default colormap is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers can sometimes washout the colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_outliers = ds.air.isel(time=0).copy()\n",
    "air_outliers[0, 0] = 100\n",
    "air_outliers[-1, -1] = 400\n",
    "air_outliers.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_outliers.plot(robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `robust=True` uses the 2nd and 98th percentiles of the data to compute the color limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby and \"split-apply-combine\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray implements the \"split-apply-combine\" paradigm with `groupby`. This works really well for calculating climatologies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.groupby('time.season').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.groupby('time.month').mean('time') #.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clim = ds.air.groupby('time.month').mean('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also do arithmetic with groupby objects, which repeats the arithmetic over each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anomalies = ds.groupby('time.month') - clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies.air.plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies.air.sel(time= '2013-02').plot() # Find all the values for February"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample adjusts a time series to a new resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmin = ds.air.resample('1D', dim='time', how='min')  # Resample to one day '1D\n",
    "tmax = ds.air.resample('1D', dim='time', how='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_extremes = xr.Dataset({'tmin': tmin, 'tmax': tmax})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_extremes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of graphics (1D, 2D - contour, Facet plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting on maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12, 4))\n",
    "# Define the map projection of the plots\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "# ax is an empty plot. We now plot the variable sw_avg onto ax\n",
    "ds.air.mean(dim='time').plot(ax=ax, transform=ccrs.PlateCarree()) \n",
    "# the keyword \"transform\" tells the function in which projection the data is stored \n",
    "ax.coastlines(); ax.gridlines(); # Add gridlines and coastlines to the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=ccrs.Orthographic(-80, 35))\n",
    "ds.air.isel(time=0).plot.contourf(ax=ax, transform=ccrs.PlateCarree());\n",
    "ax.set_global(); ax.coastlines();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "[Pandas](http://pandas.pydata.org) is the best way to work with tabular data (e.g., CSV files) in Python. It's also a highly flexible data analysis tool, with way more functionality than xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = ds.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides very robust tools for reading and writing CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(10).to_csv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, it's just as easy to convert back from pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.Dataset.from_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using pandas 0.18 or newer, you can write `df.to_xarray()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things you can do with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical visualization with [Seaborn](https://stanford.edu/~mwaskom/software/seaborn/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "data = (ds_extremes\n",
    "        .sel_points(lat=[41.8781, 37.7749], lon=[360-87.6298, 360-122.4194],\n",
    "                    method='nearest', tolerance=3,\n",
    "                    dim=xr.DataArray(['Chicago', 'San Francisco'],\n",
    "                                     name='location', dims='location'))\n",
    "        .to_dataframe()\n",
    "        .reset_index()\n",
    "        .assign(month=lambda x: x.time.dt.month))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.violinplot('month', 'tmax', 'location', data=data, split=True, inner=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xarray also works for data that doesn't fit in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a quick demo of [how xarray can leverage dask](http://xarray.pydata.org/en/stable/dask.html) to work with data that doesn't fit in memory. This lets xarray substitute for tools like `cdo` and `nco`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tell dask we want to use 4 threads (one for each core we have):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import glob2\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "dask.set_options(pool=ThreadPool(16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a bunch of netCDF files from disk using `xarray.open_mfdataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listy = glob2.glob(\"N:\\\\Wat-Data\\\\ISI-MIP1\\\\multi-GHM_output\\\\PCRGLOBWB\\\\tmp\\\\pcrglobwb_hadgem2-es_rcp8p5_nosoc_dis_daily_203*.nc\")\n",
    "#listy.extend(glob2.glob(\"N:\\\\Wat-Data\\\\ISI-MIP1\\\\multi-GHM_output\\\\PCRGLOBWB\\\\tmp\\\\pcrglobwb_hadgem2-es_rcp8p5_nosoc_dis_daily_202*.nc\"))\n",
    "#listy.extend(glob2.glob(\"N:\\\\Wat-Data\\\\ISI-MIP1\\\\multi-GHM_output\\\\PCRGLOBWB\\\\tmp\\\\pcrglobwb_hadgem2-es_rcp8p5_nosoc_dis_daily_203*.nc\"))\n",
    "ds = xr.open_mfdataset(listy, chunks={'lon': 360},concat_dim = 'time') \n",
    "ds.nbytes * (2 **-30)  #How many gigabytes of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(listy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time ds_seasonal = ds.groupby('time.season').mean('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time ds_seasonal.to_netcdf('n:\\\\wat-data\\\\ds_seasonal2.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_seasonal.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_seasonal['dis']\n",
    " .sel(season=['DJF', 'MAM', 'JJA', 'SON'])\n",
    " .plot(col='season', size=3, cmap='Spectral_r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dask.set_options(pool=ThreadPool(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time ds_month = ds.groupby('time.month').mean('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###We can also use split-apply-combine to use our own functions in an efficient way.\n",
    "For example to calculate percentiles\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_pct(x):\n",
    "    pcts=[90,80,70]\n",
    "    ds_pcts=np.percentile(x,pcts,0)\n",
    "    return xr.DataArray(ds_pcts)\n",
    "dask.set_options(pool=ThreadPool(12))\n",
    "%time ds_new = ds.dis.groupby('time.month').apply(ds_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_new = ds_new.to_dataset(name='ds_pcts')\n",
    "ds_new.rename({'dim_0': 'pcts','dim_1': 'lat','dim_2':'lon'}, inplace=True)\n",
    "ds_new['pcts'] = [90,80,70]\n",
    "ds_new['lat'] = ds.lat\n",
    "ds_new['lon'] = ds.lon\n",
    "ds_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_sqrt(x):\n",
    "    ds_sqrs=np.sqrt(x)\n",
    "    return xr.DataArray(ds_sqrs)\n",
    "dask.set_options(pool=ThreadPool(16))\n",
    "%time ds_new = ds.dis.groupby('time.month').apply(ds_sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.set_options(pool=ThreadPool(32))\n",
    "%time ds_new = ds.dis.groupby('time.month').apply(ds_sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Open a dataset of powerplants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details, read this blog post: http://continuum.io/blog/xray-dask"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
